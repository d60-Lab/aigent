#!/usr/bin/env python3
"""
Text-to-Video AI Agent - Main Entry Point
"""

import argparse
import os
import sys
from pathlib import Path

from dotenv import load_dotenv

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from text_to_video_agent import PipelineConfig, TextToVideoAgentSync


def print_banner():
    """Print application banner"""
    print()
    print("=" * 70)
    print("   TEXT-TO-VIDEO AI AGENT")
    print("   å°†æ–‡æœ¬æè¿°è½¬æ¢ä¸ºå®Œæ•´è§†é¢‘")
    print("=" * 70)
    print()


def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(
        description="Text-to-Video AI Agent - æ–‡ç”Ÿè§†é¢‘ AI åŠ©æ‰‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ç”Ÿæˆå•åœºæ™¯è§†é¢‘
  python main.py --description "ç¾ä¸½çš„æ—¥è½" --audio "ä¸€å¤©ç»“æŸäº†"

  # ä½¿ç”¨é…ç½®æ–‡ä»¶ç”Ÿæˆå¤šåœºæ™¯è§†é¢‘
  python main.py --config scenes.json

  # æŒ‡å®šè¾“å‡ºæ–‡ä»¶å
  python main.py --description "å±±æ™¯" --output my_video
        """,
    )

    parser.add_argument("--description", "-d", help="è§†é¢‘åœºæ™¯æè¿°ï¼ˆå•åœºæ™¯æ¨¡å¼ï¼‰")

    parser.add_argument("--audio", "-a", help="éŸ³é¢‘æ—ç™½æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰")

    parser.add_argument("--motion", "-m", help="è¿åŠ¨æè¿°ï¼ˆå¯é€‰ï¼‰")

    parser.add_argument(
        "--output",
        "-o",
        default="generated_video",
        help="è¾“å‡ºæ–‡ä»¶åï¼ˆé»˜è®¤: generated_videoï¼‰",
    )

    parser.add_argument("--config", "-c", help="åœºæ™¯é…ç½®æ–‡ä»¶ï¼ˆJSONæ ¼å¼ï¼Œå¤šåœºæ™¯æ¨¡å¼ï¼‰")

    parser.add_argument(
        "--no-transitions", action="store_true", help="ç¦ç”¨åœºæ™¯è¿‡æ¸¡æ•ˆæœ"
    )

    parser.add_argument(
        "--transition-duration",
        type=float,
        default=1.5,
        help="è¿‡æ¸¡æ•ˆæœæ—¶é•¿ï¼ˆç§’ï¼Œé»˜è®¤: 1.5ï¼‰",
    )
    parser.add_argument(
        "--cinematic",
        action="store_true",
        help="å¯ç”¨ç”µå½±é£æ ¼ï¼ˆ24fpsã€fadeblack è½¬åœºã€å‚è€ƒå¸§è¿è´¯ï¼‰",
    )
    parser.add_argument(
        "--fps",
        type=int,
        default=24,
        help="ç›®æ ‡å¸§ç‡ï¼ˆcinematic æ¨¡å¼ä¸‹ç”Ÿæ•ˆï¼Œé»˜è®¤: 24ï¼‰",
    )
    parser.add_argument(
        "--transition-type",
        default="fadeblack",
        help="xfade è½¬åœºç±»å‹ï¼ˆcinematic æ¨¡å¼é»˜è®¤: fadeblackï¼‰",
    )

    parser.add_argument(
        "--width", type=int, default=1920, help="è§†é¢‘å®½åº¦ï¼ˆé»˜è®¤: 1920ï¼‰"
    )

    parser.add_argument(
        "--height", type=int, default=1080, help="è§†é¢‘é«˜åº¦ï¼ˆé»˜è®¤: 1080ï¼‰"
    )

    parser.add_argument(
        "--volume", type=float, default=0.8, help="éŸ³é¢‘éŸ³é‡ï¼ˆ0.0-1.0ï¼Œé»˜è®¤: 0.8ï¼‰"
    )

    parser.add_argument(
        "--keep-temp", action="store_true", help="ä¿ç•™ä¸´æ—¶æ–‡ä»¶ï¼ˆè°ƒè¯•ç”¨ï¼‰"
    )

    parser.add_argument(
        "--plan",
        action="store_true",
        help="å¯ç”¨åœºæ™¯è§„åˆ’ï¼šå°†å•æ®µæè¿°æ‹†æˆå¤šåœºæ™¯å¹¶ç”Ÿæˆè¿è´¯è§†é¢‘",
    )
    parser.add_argument(
        "--max-scenes", type=int, default=4, help="è§„åˆ’çš„æœ€å¤§åœºæ™¯æ•°ï¼ˆé»˜è®¤: 4ï¼‰"
    )
    parser.add_argument(
        "--target-duration",
        type=float,
        default=20.0,
        help="è§„åˆ’çš„ç›®æ ‡æ€»æ—¶é•¿ï¼ˆç§’ï¼Œé»˜è®¤: 20ï¼‰",
    )
    parser.add_argument(
        "--planner-free",
        action="store_true",
        help="ä¸é™åˆ¶åœºæ™¯æ•°ä¸æ€»æ—¶é•¿ï¼Œäº¤ç”±è§„åˆ’å™¨è‡ªç”±åˆ‡åˆ†ï¼ˆæ‰§è¡Œå‰ä¼šäº¤äº’ç¡®è®¤ï¼‰",
    )

    return parser.parse_args()


def load_scenes_from_file(config_path: str):
    """Load scenes from JSON config file"""
    import json

    try:
        with open(config_path, "r", encoding="utf-8") as f:
            data = json.load(f)

        if isinstance(data, list):
            return data
        elif isinstance(data, dict) and "scenes" in data:
            return data["scenes"]
        else:
            print(f"âŒ é”™è¯¯: é…ç½®æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
            return None
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None


def main():
    """Main entry point"""
    print_banner()

    # Load environment variables
    load_dotenv()

    # Check API key
    api_key = os.getenv("POE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° POE_API_KEY")
        print()
        print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡:")
        print("  export POE_API_KEY=your_key_here")
        print()
        print("æˆ–åœ¨ .env æ–‡ä»¶ä¸­é…ç½®:")
        print("  POE_API_KEY=your_key_here")
        print()
        return 1

    # Parse arguments
    args = parse_arguments()

    # Validate arguments
    if not args.description and not args.config:
        print("âŒ é”™è¯¯: è¯·æä¾› --description æˆ– --config å‚æ•°")
        print()
        print("ä½¿ç”¨ --help æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯")
        return 1

    # Create pipeline config
    # Models can be overridden via environment variables
    # Prefer strong defaults for one-command storytelling
    tti_model = os.getenv("TEXT_TO_IMAGE_MODEL") or "FLUX-pro"
    itv_model = os.getenv("IMAGE_TO_VIDEO_MODEL") or "Runway-Gen-4-Turbo"
    tta_model = os.getenv("TEXT_TO_AUDIO_MODEL") or "hailuo-speech-02"

    # Enable simple mode (planner + cinematic) by default when only description is provided
    simple_mode = bool(args.description and not args.config)

    config = PipelineConfig(
        output_dir=Path("./output"),
        temp_dir=Path("./temp"),
        video_width=args.width,
        video_height=args.height,
        audio_volume=args.volume,
        add_transitions=not args.no_transitions,
        transition_duration=args.transition_duration,
        clean_temp=not args.keep_temp,
        text_to_image_model=tti_model,
        image_to_video_model=itv_model,
        text_to_audio_model=tta_model,
        use_planner=bool(args.plan) or os.getenv("USE_PLANNER") == "1" or simple_mode,
        max_scenes=args.max_scenes if not simple_mode else max(3, min(6, args.max_scenes)),
        target_duration=args.target_duration if not simple_mode else max(20.0, args.target_duration),
        cinematic_mode=bool(args.cinematic) or os.getenv("CINEMATIC") == "1" or simple_mode,
        cinematic_fps=args.fps,
        cinematic_transition=args.transition_type,
        auto_narrate=True,
        planner_free=bool(args.planner_free) or os.getenv("PLANNER_FREE") == "1",
    )

    # Create agent
    print("ğŸ¤– åˆå§‹åŒ– AI Agent...")
    agent = TextToVideoAgentSync(api_key, config)
    print("âœ“ Agent å°±ç»ª")
    print(f"ğŸ§  æ¨¡å‹: TTI={config.text_to_image_model}, ITV={config.image_to_video_model}, TTA={config.text_to_audio_model}")
    if config.use_planner:
        print(f"ğŸ—ºï¸  è§„åˆ’: max_scenes={config.max_scenes}, targetâ‰ˆ{config.target_duration}s, è¯­è¨€=ä¸­æ–‡, è‡ªåŠ¨æ—ç™½={config.auto_narrate}")
    print()

    # Generate video
    try:
        if args.config:
            # Multi-scene mode
            print(f"ğŸ“– ä»é…ç½®æ–‡ä»¶åŠ è½½åœºæ™¯: {args.config}")
            scenes = load_scenes_from_file(args.config)

            if not scenes:
                return 1

            print(f"âœ“ åŠ è½½äº† {len(scenes)} ä¸ªåœºæ™¯")
            print()

            result = agent.create_video(scenes=scenes, output_name=args.output)
        else:
            # Single scene mode
            print("ğŸ¬ å•åœºæ™¯æ¨¡å¼")
            print(f"æè¿°: {args.description}")
            if args.audio:
                print(f"éŸ³é¢‘: {args.audio}")
            if args.motion:
                print(f"è¿åŠ¨: {args.motion}")
            print()

            if config.use_planner:
                print("ğŸ§­ å¯ç”¨åœºæ™¯è§„åˆ’ â†’ æ‹†åˆ†ä¸ºå¤šåœºæ™¯")
                # å¦‚æœæ˜¯è‡ªç”±è§„åˆ’æ¨¡å¼ï¼Œå…ˆæ‰“å°è§„åˆ’å¹¶ç¡®è®¤
                if config.planner_free:
                    planned = agent.plan_scenes_sync(args.description)
                    print("\nğŸ“‹ è§„åˆ’é¢„è§ˆï¼š")
                    for i, s in enumerate(planned, 1):
                        print(f"  åœºæ™¯{i}: {s.get('description','')}")
                        if s.get("motion"):
                            print(f"    é•œå¤´: {s['motion']}")
                        if s.get("audio_text"):
                            print(f"    æ—ç™½: {s['audio_text']}")
                    ans = input("\næ˜¯å¦æŒ‰ä»¥ä¸Šè§„åˆ’ç”Ÿæˆè§†é¢‘ï¼Ÿ(y/N): ").strip().lower()
                    if ans not in ("y", "yes"):  # ç”¨æˆ·å–æ¶ˆ
                        print("å·²å–æ¶ˆã€‚")
                        return 0
                    result = agent.create_video(planned, output_name=args.output)
                else:
                    result = agent.create_from_description(
                        description=args.description,
                        audio_text=args.audio,
                        output_name=args.output,
                    )
            else:
                scene_data = {
                    "description": args.description,
                    "audio_text": args.audio,
                    "motion": args.motion,
                }
                result = agent.create_video(
                    scenes=[scene_data], output_name=args.output
                )

        # Display results
        print()
        print("=" * 70)

        if result.success:
            print("âœ… è§†é¢‘ç”ŸæˆæˆåŠŸï¼")
            print("=" * 70)
            print()
            print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {result.output_path}")
            print(f"â±ï¸  å¤„ç†æ—¶é—´: {result.duration:.1f} ç§’")
            print(
                f"ğŸ¬ åœºæ™¯æ•°: {result.metadata.get('successful_scenes', 0)}/{result.metadata.get('scenes_count', 0)}"
            )

            if result.metadata.get("failed_scenes", 0) > 0:
                print(f"âš ï¸  å¤±è´¥åœºæ™¯: {result.metadata['failed_scenes']}")

            print()
            print("åœºæ™¯è¯¦æƒ…:")
            for i, scene in enumerate(result.scenes, 1):
                status = "âœ“" if scene.final_path else "âœ—"
                desc = (
                    scene.description[:50] + "..."
                    if len(scene.description) > 50
                    else scene.description
                )
                print(f"  {status} åœºæ™¯ {i}: {desc}")

            return 0
        else:
            print("âŒ è§†é¢‘ç”Ÿæˆå¤±è´¥")
            print("=" * 70)
            print()
            print("é”™è¯¯ä¿¡æ¯:")
            for error in result.errors:
                print(f"  â€¢ {error}")

            print()
            print("éƒ¨åˆ†ç»“æœ:")
            for i, scene in enumerate(result.scenes, 1):
                status = "âœ“" if scene.final_path else "âœ—"
                desc = (
                    scene.description[:50] + "..."
                    if len(scene.description) > 50
                    else scene.description
                )
                print(f"  {status} åœºæ™¯ {i}: {desc}")

            return 1

    except KeyboardInterrupt:
        print()
        print("âš ï¸  ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        print()
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
